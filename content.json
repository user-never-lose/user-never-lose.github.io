{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/08/22/hello-world/"},{"title":"algorithm","text":"第一章 基本数据结构1.1 栈1.2 队列1.3 优先队列(堆)1.4 树1.5 图第二章 遍历方法的使用2.1 BFS2.2 DFS第三章 树的算法第四章 图的算法第五章 动态规划5.1 背包问题第六章 特殊经典算法第七章 特殊数据结构","link":"/2020/08/24/algorithm/"},{"title":"java","text":"第一章 类1.1 类成员&emsp;类成员包含类成员方法和类成员变量，需注意的是其声明 如 private public protected 其中private 代表的是私有，该类的实例化对象不能调用。类的内部实现时，类成员能够调用。 其中public 代表的是公开，类的实例化对象可以调用。 其中protected 代表的是保护，和private 的区别是在继承时，子类的成员可以对父类的成员进行调用。 第二章 java基本容器","link":"/2020/08/23/java/"},{"title":"linux","text":"第一章 基本命令1.1 帮助命令man [命令名称] 1.2 显示文件命令显示当前文件夹所有的显视文件 ls 显示当前文件夹所有文件包括隐藏文件 ls -l","link":"/2020/08/23/linux/"},{"title":"markdown","text":"第一章 基本语法1.1 首行缩进输入一个空格 &amp;ensp; 输入两个空格 &amp;emsp; 1.2 插入代码使用tab键或四个连续空格","link":"/2020/08/23/markdown/"},{"title":"netty","text":"第一章 服务器端1.1 主从线程池","link":"/2020/08/23/netty/"},{"title":"pytorch","text":"第一章 张量、数组及数据的加载&emsp;张量是神经网络计算的基础，使用numpy和torch很容易进行数组和张量的转换。通过加载数据集里的数据到数组，再通过数组转换成张量进行运算。 1.1 numpy的属性ndim 维度shape 张量形状size 元素个数 第二章 torch基本方法1）torch.as_tensor(data, dtype=None, device=None) → Tensor &emsp;将data 转换成tensor 张量，data 可以是list,tuple,numpy,scalar 等数据。 &emsp;dtype 返回的张量的数据类型，如果是None，则用data 的数据类型。 &emsp;device 设置的是返回的张量将运行在某个GPU或者CPU设备上。 &gt;&gt;&gt; a = numpy.array([1, 2, 3]) &gt;&gt;&gt; t = torch.as_tensor(a) &gt;&gt;&gt; t tensor([ 1, 2, 3]) &gt;&gt;&gt; t[0] = -1 &gt;&gt;&gt; a array([-1, 2, 3]) &gt;&gt;&gt; a = numpy.array([1, 2, 3]) &gt;&gt;&gt; t = torch.as_tensor(a, device=torch.device('cuda')) &gt;&gt;&gt; t tensor([ 1, 2, 3]) &gt;&gt;&gt; t[0] = -1 &gt;&gt;&gt; a array([1, 2, 3]) 2)","link":"/2020/08/23/pytorch/"},{"title":"readme","text":"","link":"/2020/08/23/readme/"},{"title":"test","text":"","link":"/2020/08/24/test/"}],"tags":[],"categories":[]}